{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc769f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3bc22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_preprocessing.csv')\n",
    "test_df = pd.read_csv('test_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02884eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>7604</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>worldnews fallen powerlines on glink tram upda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>7605</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>on the flip side im at walmart and there is a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>7606</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>suicide bomber kills  in saudi security site m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>7608</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>7612</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 keyword location  \\\n",
       "0              0    None     None   \n",
       "1              1    None     None   \n",
       "2              2    None     None   \n",
       "3              3    None     None   \n",
       "4              4    None     None   \n",
       "...          ...     ...      ...   \n",
       "7498        7604    None     None   \n",
       "7499        7605    None     None   \n",
       "7500        7606    None     None   \n",
       "7501        7608    None     None   \n",
       "7502        7612    None     None   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason of this earthquake ma...       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     all residents asked to shelter in place are be...       1  \n",
       "3      people receive wildfires evacuation orders in...       1  \n",
       "4     just got sent this photo from ruby alaska as s...       1  \n",
       "...                                                 ...     ...  \n",
       "7498  worldnews fallen powerlines on glink tram upda...       1  \n",
       "7499  on the flip side im at walmart and there is a ...       1  \n",
       "7500  suicide bomber kills  in saudi security site m...       1  \n",
       "7501  two giant cranes holding a bridge collapse int...       1  \n",
       "7502  the latest more homes razed by northern califo...       1  \n",
       "\n",
       "[7503 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac03dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "keyword       0\n",
       "location      0\n",
       "text          0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0f4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df['text']\n",
    "y = train_df['target']\n",
    "x1 = test_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a267bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_text(text):\n",
    "    text = text.replace(\"KEYWORD: None \",\"\")\n",
    "    text = text.replace(\"LOCATION: None \",\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073f76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx = 'KEYWORD: ' + train_df['keyword'].astype(str)     + ' LOCATION: ' + train_df['location'].astype(str)     + ' TEXT: ' + train_df['text'].astype(str)\\nx = x.apply(new_text)\\n\\ny = train_df['target']\\n\\nx1 = 'KEYWORD: ' + test_df['keyword'].astype(str)     + ' LOCATION: ' + test_df['location'].astype(str)     + ' TEXT: ' + test_df['text'].astype(str) \\nx1 = x1.apply(new_text)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x = 'KEYWORD: ' + train_df['keyword'].astype(str) \\\n",
    "    + ' LOCATION: ' + train_df['location'].astype(str) \\\n",
    "    + ' TEXT: ' + train_df['text'].astype(str)\n",
    "x = x.apply(new_text)\n",
    "\n",
    "y = train_df['target']\n",
    "\n",
    "x1 = 'KEYWORD: ' + test_df['keyword'].astype(str) \\\n",
    "    + ' LOCATION: ' + test_df['location'].astype(str) \\\n",
    "    + ' TEXT: ' + test_df['text'].astype(str) \n",
    "x1 = x1.apply(new_text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6e4275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       TEXT: our deeds are the reason of this earthqu...\n",
       "1             TEXT: forest fire near la ronge sask canada\n",
       "2       TEXT: all residents asked to shelter in place ...\n",
       "3       TEXT:  people receive wildfires evacuation ord...\n",
       "4       TEXT: just got sent this photo from ruby alask...\n",
       "                              ...                        \n",
       "7498    TEXT: worldnews fallen powerlines on glink tra...\n",
       "7499    TEXT: on the flip side im at walmart and there...\n",
       "7500    TEXT: suicide bomber kills  in saudi security ...\n",
       "7501    TEXT: two giant cranes holding a bridge collap...\n",
       "7502    TEXT: the latest more homes razed by northern ...\n",
       "Length: 7503, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067159e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533acdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dba9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng CountVectorizer để tạo đặc trưng\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_features = vectorizer.fit_transform(x_train)\n",
    "x_test_features = vectorizer.transform(x_test)\n",
    "test = vectorizer.transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng TfidfVectorizer để tạo đặc trưng\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train_features = vectorizer.fit_transform(x_train)\n",
    "x_test_features = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_svc = svc_model.predict(x_test_features)\n",
    "\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_svc, y_test)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Huấn luyện mô hình RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_rf = rf_model.predict(x_test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_rf, y_test)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55173990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Huấn luyện mô hình xbg\n",
    "xbg_model = xgb.XGBClassifier()\n",
    "xbg_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_xgb = xbg_model.predict(x_test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_xgb, y_test)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Huấn luyện mô hình Multinomial Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_nb = nb_model.predict(x_test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_nb, y_test)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Huấn luyện mô hình lr\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train_features, y_train)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_lr = lr_model.predict(x_test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_lr, y_test)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svc = svc_model.predict(test)\n",
    "predictions_nb = nb_model.predict(test)\n",
    "predictions_lr = lr_model.predict(test)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Kết hợp kết quả từ ba mô hình bằng phương pháp Max Vote\n",
    "vote_counts = None\n",
    "combined_predictions = []\n",
    "for i in range(len(predictions_svc)):\n",
    "    # Tạo danh sách kết quả từ ba mô hình tại vị trí i\n",
    "    votes = [predictions_svc[i], predictions_nb[i],predictions_lr[i]]\n",
    "    # Đếm số lần xuất hiện của từng lớp dự đoán\n",
    "    vote_counts = Counter(votes)\n",
    "    # Lấy lớp dự đoán phổ biến nhất\n",
    "    majority_vote = vote_counts.most_common(1)[0][0]\n",
    "    # Thêm kết quả vào danh sách kết hợp\n",
    "    combined_predictions.append(majority_vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740be0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = pd.DataFrame({'id': test_df['id'], 'target': combined_predictions})\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_accuracy = accuracy_score(predictions_nb, predictions_svc)\n",
    "#print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb12f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d04dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3de168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 16:33:44.957271: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-25 16:33:44.974128: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-25 16:33:45.082472: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-25 16:33:45.083081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-25 16:33:45.704600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae96961",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(x.values, y.values, test_size=.20, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02faa096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "x_train_encoded = tokenizer.batch_encode_plus(\n",
    "    train_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Fine-tune BERT\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1f1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "151/151 [==============================] - 749s 5s/step - loss: 0.4929 - accuracy: 0.7773 - val_loss: 0.3998 - val_accuracy: 0.8326\n",
      "Epoch 2/3\n",
      "151/151 [==============================] - 712s 5s/step - loss: 0.3706 - accuracy: 0.8523 - val_loss: 0.3751 - val_accuracy: 0.8443\n",
      "Epoch 3/3\n",
      "151/151 [==============================] - 690s 5s/step - loss: 0.3097 - accuracy: 0.8846 - val_loss: 0.4126 - val_accuracy: 0.8393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9f03b9640>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train_encoded['input_ids'],\n",
    "    y=train_labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66058f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 54s 1s/step - loss: 0.4282 - accuracy: 0.8274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4282246530056, 0.8274483680725098]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoded = tokenizer.batch_encode_plus(\n",
    "    val_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "model.evaluate(\n",
    "    x=x_test_encoded['input_ids'],\n",
    "    y=val_labels,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6594189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 125s 1s/step\n"
     ]
    }
   ],
   "source": [
    "x_test_encoded = tokenizer.batch_encode_plus(\n",
    "    x1.values,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_encoded['input_ids'])\n",
    "\n",
    "# Extract predicted labels\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea6f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_df['id'], 'target': predicted_labels})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede53f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
