{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1424cdc",
   "metadata": {},
   "source": [
    "# Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b1ac1",
   "metadata": {},
   "source": [
    "Bài toán này nhóm em thử với nhiều mô hình khác nhau, bao gồm các mô hình học máy truyền thống và mô hình học sâu. \n",
    "\n",
    "Đối với các mô hình học máy truyền thống, nhóm em train trên các mô hình quen thuộc như: SVC, Random Forest, XgBoost, Navie Bayes và Logistic Regression.\n",
    "\n",
    "Đối với mô hình học sâu, nhóm em sử dụng RoBERTa (Robustly Optimized BERT Approach), đây là một mô hình ngôn ngữ rất mạnh trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f8203",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu từ file sau khi tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec95afc",
   "metadata": {},
   "source": [
    "(Nếu gộp 1 file thì phần này bỏ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea43f183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.805305Z",
     "iopub.status.busy": "2023-06-29T10:19:25.804972Z",
     "iopub.status.idle": "2023-06-29T10:19:25.810092Z",
     "shell.execute_reply": "2023-06-29T10:19:25.809056Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.805275Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363e7f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.812169Z",
     "iopub.status.busy": "2023-06-29T10:19:25.811811Z",
     "iopub.status.idle": "2023-06-29T10:19:25.819158Z",
     "shell.execute_reply": "2023-06-29T10:19:25.818228Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.812126Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_preprocessing.csv')\n",
    "test_df = pd.read_csv('test_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0624f0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.821300Z",
     "iopub.status.busy": "2023-06-29T10:19:25.820635Z",
     "iopub.status.idle": "2023-06-29T10:19:25.838020Z",
     "shell.execute_reply": "2023-06-29T10:19:25.837051Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.821265Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deeds reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>7604</td>\n",
       "      <td>10863</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>worldnews fallen powerlines glink tram update ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>7605</td>\n",
       "      <td>10864</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>flip im walmart bomb evacuate stay tuned blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>7606</td>\n",
       "      <td>10866</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>suicide bomber kills saudi security site mosqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>7608</td>\n",
       "      <td>10869</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>giant cranes holding bridge collapse nearby homes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>7612</td>\n",
       "      <td>10873</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>latest homes razed northern california wildfir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7501 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     id keyword location  \\\n",
       "0              0      1    None     None   \n",
       "1              1      4    None     None   \n",
       "2              2      5    None     None   \n",
       "3              3      6    None     None   \n",
       "4              4      7    None     None   \n",
       "...          ...    ...     ...      ...   \n",
       "7496        7604  10863    None     None   \n",
       "7497        7605  10864    None     None   \n",
       "7498        7606  10866    None     None   \n",
       "7499        7608  10869    None     None   \n",
       "7500        7612  10873    None     None   \n",
       "\n",
       "                                                   text  target  \n",
       "0                 deeds reason earthquake allah forgive       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     residents asked shelter place notified officer...       1  \n",
       "3     people receive wildfires evacuation orders cal...       1  \n",
       "4     got sent photo ruby alaska smoke wildfires pou...       1  \n",
       "...                                                 ...     ...  \n",
       "7496  worldnews fallen powerlines glink tram update ...       1  \n",
       "7497      flip im walmart bomb evacuate stay tuned blow       1  \n",
       "7498  suicide bomber kills saudi security site mosqu...       1  \n",
       "7499  giant cranes holding bridge collapse nearby homes       1  \n",
       "7500  latest homes razed northern california wildfir...       1  \n",
       "\n",
       "[7501 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949d1f1",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2dfe0",
   "metadata": {},
   "source": [
    "Chúng ta chỉ sử dụng thông tin từ cột `text` để train cho mô hình. Nhóm đã thử sử dụng kết hợp cả thông tin của cột `keyword` và `location` nhưng khi chạy thì ra kết quả thấp hơn đáng kể. Kết quả trong trường hợp chỉ sử dụng duy nhất cột `text` là tốt nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b61926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.839808Z",
     "iopub.status.busy": "2023-06-29T10:19:25.839339Z",
     "iopub.status.idle": "2023-06-29T10:19:25.844930Z",
     "shell.execute_reply": "2023-06-29T10:19:25.844061Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.839777Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = train_df['text']\n",
    "y = train_df['target']\n",
    "x1 = test_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb80417",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta tiến hành chia dữ liệu có được thành các tập train và test để phục vụ cho quá trình training và testing. Dữ liệu được chia với `test_size` = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d018a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(x.values, y.values, test_size=.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18a0cb",
   "metadata": {},
   "source": [
    "Đối với các mô hình học máy truyền thống, nhóm sử dụng **TF-IDF** để tạo đặc trưng trước khi đưa dữ liệu vào mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac27dc",
   "metadata": {},
   "source": [
    "TF-IDF là viết tắt của “Term Frequency, Inverse Document Frequency” - tạm dịch “Tần suất thuật ngữ, Tần suất tài liệu nghịch đảo”. Đó là một cách để chấm điểm tầm quan trọng của các từ (hoặc \"các thuật ngữ\") dựa trên tần suất xuất hiện của chúng xuất hiện trên nhiều tài liệu dựa trên quy tắc sau:\n",
    "\n",
    "- Nếu một từ xuất hiện thường xuyên trong tài liệu, điều đó rất quan trọng. Cho từ này điểm cao.\n",
    "- Nhưng nếu một từ xuất hiện trong nhiều tài liệu, thì đó không phải là mã định danh duy nhất. Cho từ đó điểm thấp.\n",
    "\n",
    "Do đó, những từ phổ biến như `the` và `for` xuất hiện trong nhiều tài liệu sẽ được scaled down. Các từ xuất hiện thường xuyên trong một tài liệu sẽ được scaled up.\n",
    "\n",
    "Với những giải thích trên, ta có công thức tính trọng số của một từ trong tài liệu trong ngữ liệu như sau:\n",
    "\n",
    "$$w_{i,j} = tf_{i,j} \\cdot idf_i = tf_{i,j} \\cdot log(\\frac {N}{df_i})$$\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- $tf_{i,j}$: Tần suất xuất hiện của i trong j\n",
    "- $N$: Tổng số tài liệu\n",
    "- $df_i$: Số tài liệu chứa i\n",
    "\n",
    "**Reference:** https://medium.com/analytics-vidhya/an-introduction-to-tf-idf-using-python-5f9d1a343f77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cde718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a37286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng TfidfVectorizer để tạo đặc trưng\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "test_features = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1353e",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf895fb",
   "metadata": {},
   "source": [
    "Sau khi đã có các đặc trưng, việc còn lại chỉ là sử dụng các thư viện học máy như sklearn, gọi hàm rồi quăng dữ liệu vào và đợi kết quả thôi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c198f539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8027981345769487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Huấn luyện mô hình SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(train_features, train_labels)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_svc = svc_model.predict(test_features)\n",
    "\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_svc, test_labels)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8d4f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7841439040639574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Huấn luyện mô hình RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(train_features, train_labels)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_rf = rf_model.predict(test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_rf, test_labels)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c21e532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7721518987341772\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Huấn luyện mô hình xbg\n",
    "xbg_model = xgb.XGBClassifier()\n",
    "xbg_model.fit(train_features, train_labels)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_xgb = xbg_model.predict(test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_xgb, test_labels)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec22dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.810126582278481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Huấn luyện mô hình Multinomial Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_features, train_labels)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_nb = nb_model.predict(test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_nb, test_labels)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ecf776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8061292471685543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Huấn luyện mô hình lr\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(train_features, train_labels)\n",
    "\n",
    "# Dự đoán kết quả\n",
    "predictions_lr = lr_model.predict(test_features)\n",
    "\n",
    "val_accuracy = accuracy_score(predictions_lr, test_labels)\n",
    "print('Validation Accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2b5c5",
   "metadata": {},
   "source": [
    "**Nhận xét:**\n",
    "- So sánh kết của giữa các mô hình thì có vẻ Random Forest và XgBoost kết quả có hơi bị thọt so với các mô hình còn lại. \n",
    "- Có vẻ như mô hình dựa trên việc sử dụng Decision Tree không tốt lắm (tệ) trong bài toán text classification. \n",
    "- Các mô hình chạy ra kết quả cũng tốt thật đấy, nhưng cũng chỉ tầm được mức 0.8 là cao nhất. Mục tiêu của nhóm là phải lọt được top 10%. Kết quả của các mô hình trên chỉ giúp đạt được top 50% (quá tệ), thế nên cần lựa chọn một mô hình tốt hơn cho bài toán này nếu muốn kết quả tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6e0f7",
   "metadata": {},
   "source": [
    "Nhóm cũng đã thử tìm cách để cải thiện kết quả của các mô hình truyền thống, như điều chỉnh lại 1 số chỗ ở phần tiền xử lý dữ liệu, điều chỉnh tham số mô hình,... Nhưng kết quả vẫn không thay đổi đáng kể 1 tý nào.\n",
    "\n",
    "Sau khi tìm hiểu \"1 ít\" về lĩnh vực xử lý ngôn ngữ tự nhiên, nhóm phát hiện ra rằng các mô hình nổi bật trong xử lý ngôn ngữ tự nhiên đặc biệt là với task text classification đa số đều là các mô hình học sâu, trong đó cái tên xuất hiện nhiều nhất là BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd87ec3",
   "metadata": {},
   "source": [
    "Ý tưởng để giải quyết bài toán là sử dụng mô hình đã pre-train từ một tập dữ liệu rất rất lớn trước, sau đó điều chỉnh tham số của mô hình (fine-tuning) rồi train trên downstream task (tức là bài toán của chúng ta). Việc mô hình ngôn ngữ đã pre-train thực sự đem lại hiệu quả rất lớn trong việc xử lý các tác vụ của xử lý ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a01fa",
   "metadata": {},
   "source": [
    "BERT về cơ bản là một kiến trúc transformer được đào tạo để học cách biểu diễn ngôn ngữ. Nó chủ yếu khác với những mô hình ngôn ngữ trước đây là do khả năng hiểu được ngữ cảnh từ cả 2 phía của câu (trái và phải của chính từ đó) thay vì chỉ sử dụng thông tin từ trái sang phải (left-to-right) hoặc ngược lại. Từ đó, cho phép nắm bắt được sự phụ thuộc và ý nghĩa toàn diện hơn trong câu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e612a16",
   "metadata": {},
   "source": [
    "Sau khi thử BERT và các mô hình khác nhau được xây dựng dựa trên BERT, nhóm em đã thành công chọn một mô hình tốt nhất đó là RoBERTa.\n",
    "\n",
    "RoBERTa tương tự như BERT về kiến trúc, nhưng nó đã trải qua một số cải tiến trong quá trình huấn luyện. Mục tiêu của RoBERTa là cải thiện hiệu suất so với BERT thông qua việc tinh chỉnh quá trình huấn luyện và sử dụng các siêu tham số khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965a9e0",
   "metadata": {},
   "source": [
    "Một số khác biệt giữa RoBERTa và BERT:\n",
    "\n",
    "- **Kích thước dữ liệu huấn luyện:** RoBERTa được tiền huấn luyện với lượng dữ liệu lớn hơn BERT gấp 10 lần (160GB và 16GB). Điều này giúp RoBERTa học được nhiều đặc trưng ngôn ngữ phổ quát hơn và cải thiện khả năng hiểu ngữ nghĩa.\n",
    "- **Mặt nạ:** BERT được đào tạo với mặt nạ tĩnh, nghĩa là mặt nạ được khởi tạo 1 lần và được đưa vào huấn luyện trong mỗi epoch. Để có sự đa dạng hơn trong dữ liệu đào tạo cho mỗi epoch thì RoBERTa được áp dụng mặt nạ động. Hiệu suất của mô hình được đào tạo với mặt nạ động tốt hơn một chút hoặc ít nhất là tương đương với phương pháp ban đầu được sử dụng mặt nạ tĩnh.\n",
    "- **Loại bỏ NSP:** RoBERTa không cần phải giới hạn đầu vào theo cặp câu và có thể sử dụng các cặp câu ngẫu nhiên để tăng đa dạng dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "614c7eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.864608Z",
     "iopub.status.busy": "2023-06-29T10:19:25.864031Z",
     "iopub.status.idle": "2023-06-29T10:19:25.870228Z",
     "shell.execute_reply": "2023-06-29T10:19:25.868539Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.864572Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 19:02:45.693708: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-29 19:02:45.717498: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 19:02:45.823718: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 19:02:45.824933: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 19:02:46.464104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "from transformers import TFRobertaForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcd0e79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.851024Z",
     "iopub.status.busy": "2023-06-29T10:19:25.850391Z",
     "iopub.status.idle": "2023-06-29T10:19:25.862686Z",
     "shell.execute_reply": "2023-06-29T10:19:25.861652Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.850988Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(x.values, y.values, test_size=.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b7ba2",
   "metadata": {},
   "source": [
    "Nhóm em sử dụng RoBERTa cho bài toán này bằng việc import `TFRobertaForSequenceClassification` trong thư viện `transformers`.\n",
    "\n",
    "Việc sử dụng mô hình từ thư viện này rất đơn giản, chỉ cần khởi tạo mô hình đã Pre-training với RoBERTa Base.\n",
    "\n",
    "Sau khi khởi tạo mô hình, ta sẽ Encoding input cho phù hợp với đầu vào của mô hình (đây có thể xem như là bước tạo đặc trưng cho mô hình). \n",
    "\n",
    "Tiếp theo sẽ là bước tinh chỉnh mô hình (fine-tuning) và train mô hình. Sau nhiều lần thử với các tham số khác nhau, nhóm em chọn learning rate (adam) là 3e-5, batch size là 32, và epoch là 2 thì sẽ có được kết quả tốt nhất. \n",
    "\n",
    "Cuối cùng là evaluate model trên dữ liệu test để thu được kết quả và đánh giá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59485bab",
   "metadata": {},
   "source": [
    "Khởi tạo mô hình và Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47fb081c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:25.872836Z",
     "iopub.status.busy": "2023-06-29T10:19:25.871943Z",
     "iopub.status.idle": "2023-06-29T10:19:28.197240Z",
     "shell.execute_reply": "2023-06-29T10:19:28.196406Z",
     "shell.execute_reply.started": "2023-06-29T10:19:25.872800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình và Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feeb59d",
   "metadata": {},
   "source": [
    "Encoding input cho phù hợp với đầu vào của mô hình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "025a06c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:28.199316Z",
     "iopub.status.busy": "2023-06-29T10:19:28.198944Z",
     "iopub.status.idle": "2023-06-29T10:19:31.020740Z",
     "shell.execute_reply": "2023-06-29T10:19:31.019796Z",
     "shell.execute_reply.started": "2023-06-29T10:19:28.199278Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encode train input\n",
    "encoded_inputs = tokenizer(train_texts.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "labels = tf.constant(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3703619",
   "metadata": {},
   "source": [
    "Điều chỉnh tham số cho mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4cee0344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:31.022505Z",
     "iopub.status.busy": "2023-06-29T10:19:31.022067Z",
     "iopub.status.idle": "2023-06-29T10:19:31.034500Z",
     "shell.execute_reply": "2023-06-29T10:19:31.033540Z",
     "shell.execute_reply.started": "2023-06-29T10:19:31.022474Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training parameters\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d963aa",
   "metadata": {},
   "source": [
    "Compile và train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49812867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:19:31.036692Z",
     "iopub.status.busy": "2023-06-29T10:19:31.036318Z",
     "iopub.status.idle": "2023-06-29T10:24:18.819150Z",
     "shell.execute_reply": "2023-06-29T10:24:18.818177Z",
     "shell.execute_reply.started": "2023-06-29T10:19:31.036662Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "188/188 [==============================] - 157s 585ms/step - loss: 0.5338 - accuracy: 0.7319\n",
      "Epoch 2/2\n",
      "188/188 [==============================] - 107s 570ms/step - loss: 0.3933 - accuracy: 0.8341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e0a60342260>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "model.fit(encoded_inputs.input_ids, labels, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df9bbf",
   "metadata": {},
   "source": [
    "Đánh giá kết quả của model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df93b7ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:24:18.830404Z",
     "iopub.status.busy": "2023-06-29T10:24:18.829735Z",
     "iopub.status.idle": "2023-06-29T10:24:30.644863Z",
     "shell.execute_reply": "2023-06-29T10:24:30.643740Z",
     "shell.execute_reply.started": "2023-06-29T10:24:18.830370Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 11s 173ms/step - loss: 0.3853 - accuracy: 0.8448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38526058197021484, 0.8447701334953308]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode test input\n",
    "test_inputs = tokenizer(test_texts.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "#labels = tf.constant(test_labels.tolist())\n",
    "\n",
    "\n",
    "model.evaluate(\n",
    "    x=test_inputs.input_ids,\n",
    "    y=test_labels,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f08e82",
   "metadata": {},
   "source": [
    "Kết quả của mô hình đạt được rất tốt, vượt trội rất nhiều so với các mô hình truyền thống. Với kết quả này nhóm tự tin đạt vào top 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993c9e8",
   "metadata": {},
   "source": [
    "Vì mô hình này tốt nhất nên nhóm sử dụng mô hình này để thực hiện việc dự đoán trên tập test và nộp kết quả đạt được lên Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0652b744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:24:30.651760Z",
     "iopub.status.busy": "2023-06-29T10:24:30.649323Z",
     "iopub.status.idle": "2023-06-29T10:24:52.941008Z",
     "shell.execute_reply": "2023-06-29T10:24:52.939837Z",
     "shell.execute_reply.started": "2023-06-29T10:24:30.651723Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 21s 171ms/step\n"
     ]
    }
   ],
   "source": [
    "#Encode predict input\n",
    "predict_inputs = tokenizer(x1.tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "# Make predictions\n",
    "predictions = model.predict(predict_inputs.input_ids)\n",
    "\n",
    "# Extract predicted labels\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3544d22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T10:24:52.944786Z",
     "iopub.status.busy": "2023-06-29T10:24:52.944435Z",
     "iopub.status.idle": "2023-06-29T10:24:52.960930Z",
     "shell.execute_reply": "2023-06-29T10:24:52.959976Z",
     "shell.execute_reply.started": "2023-06-29T10:24:52.944758Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_df['id'], 'target': predicted_labels})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8c5db",
   "metadata": {},
   "source": [
    "Kết quả nhóm đạt dược: 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.683972,
   "end_time": "2023-06-28T09:26:20.731076",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-28T09:26:06.047104",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
